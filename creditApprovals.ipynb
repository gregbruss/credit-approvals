{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "creditApprovals.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1avD4ogxA19mXMJzgZczTEXA0edgH_ePy",
      "authorship_tag": "ABX9TyNtXUcXqABSGhmZZGKFsXWQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gregbruss/credit-approvals/blob/main/creditApprovals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isWS7jCvqpj7"
      },
      "source": [
        "# Credit Card Approvals\n",
        "\n",
        "The task of approving people for credit in terms of their creditworthiness is universally done by every major bank and financial institution. These organizations typically receive hundreds of thousands of these types of applications per year. The decision given in any case is a variety of factors, most typically relying on someone's income and employment status, their level of debt, and their prior credit history. Due to the nature of this type of task, it is well suited to machine learning. In this notebook I build an ML model which makes use of data from the UCI Machine Learning repository (https://archive.ics.uci.edu/ml/datasets/credit+approval).\n",
        "\n",
        "The data has been anonymized, and is interesting as it contains a very nice mix of attributes: continuous, categorical, nominal in small ranges and in large ranges. \n",
        "\n",
        "Advancements in credit approval technology have saved banks and other financial institutions literally tens of thousands of hours. This analysis uses a variety of widely-known preprocessing steps such as scaling, label encoding, and missing value imputation, as well as ML techniques such as Logistic Regression, and Hyperparameter Tuning using GridSearch.\n",
        "\n",
        "The final model is able to predict whether a person was approved or not with an accuracy of 85%.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Q2cukvbApKyh",
        "outputId": "4d9cd361-13db-49c6-97b9-1b46d86f3c4e"
      },
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "applications = pd.read_csv('/content/drive/MyDrive/projects/Credit Approvals/datasets/cc_approvals.data', header=None)\n",
        "# Inspect data\n",
        "applications.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrhtY0JOIJs"
      },
      "source": [
        "### Inspecting the Applications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvbSbIRAONnh",
        "outputId": "4e57dc05-94c3-40fd-bf8a-ccbc38be3135"
      },
      "source": [
        "cc_summary_statistics = applications.describe()\n",
        "print(cc_summary_statistics)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               2           7          10             14\n",
            "count  690.000000  690.000000  690.00000     690.000000\n",
            "mean     4.758725    2.223406    2.40000    1017.385507\n",
            "std      4.978163    3.346513    4.86294    5210.102598\n",
            "min      0.000000    0.000000    0.00000       0.000000\n",
            "25%      1.000000    0.165000    0.00000       0.000000\n",
            "50%      2.750000    1.000000    0.00000       5.000000\n",
            "75%      7.207500    2.625000    3.00000     395.500000\n",
            "max     28.000000   28.500000   67.00000  100000.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRvLZH6NPFC6",
        "outputId": "def249c2-c93d-4c8d-cc74-808a5beab231"
      },
      "source": [
        "# Dataframe Information\n",
        "applications_info = applications.info()\n",
        "print(applications_info)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       690 non-null    object \n",
            " 1   1       690 non-null    object \n",
            " 2   2       690 non-null    float64\n",
            " 3   3       690 non-null    object \n",
            " 4   4       690 non-null    object \n",
            " 5   5       690 non-null    object \n",
            " 6   6       690 non-null    object \n",
            " 7   7       690 non-null    float64\n",
            " 8   8       690 non-null    object \n",
            " 9   9       690 non-null    object \n",
            " 10  10      690 non-null    int64  \n",
            " 11  11      690 non-null    object \n",
            " 12  12      690 non-null    object \n",
            " 13  13      690 non-null    object \n",
            " 14  14      690 non-null    int64  \n",
            " 15  15      690 non-null    object \n",
            "dtypes: float64(2), int64(2), object(12)\n",
            "memory usage: 86.4+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X3JM788QHVD"
      },
      "source": [
        "Dataset contains varying data types: float64, int64, and object types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "iCoD8uOWPtuJ",
        "outputId": "603189a3-d101-4765-baf9-c20664610ef3"
      },
      "source": [
        "applications.tail(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>b</td>\n",
              "      <td>19.50</td>\n",
              "      <td>0.290</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>k</td>\n",
              "      <td>v</td>\n",
              "      <td>0.290</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>364</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.000</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>d</td>\n",
              "      <td>h</td>\n",
              "      <td>3.000</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00176</td>\n",
              "      <td>537</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>b</td>\n",
              "      <td>17.08</td>\n",
              "      <td>3.290</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>i</td>\n",
              "      <td>v</td>\n",
              "      <td>0.335</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00140</td>\n",
              "      <td>2</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>b</td>\n",
              "      <td>36.42</td>\n",
              "      <td>0.750</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>d</td>\n",
              "      <td>v</td>\n",
              "      <td>0.585</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00240</td>\n",
              "      <td>3</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>b</td>\n",
              "      <td>40.58</td>\n",
              "      <td>3.290</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>m</td>\n",
              "      <td>v</td>\n",
              "      <td>3.500</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>s</td>\n",
              "      <td>00400</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>b</td>\n",
              "      <td>21.08</td>\n",
              "      <td>10.085</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>e</td>\n",
              "      <td>h</td>\n",
              "      <td>1.250</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00260</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>a</td>\n",
              "      <td>22.67</td>\n",
              "      <td>0.750</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>v</td>\n",
              "      <td>2.000</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>2</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00200</td>\n",
              "      <td>394</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>a</td>\n",
              "      <td>25.25</td>\n",
              "      <td>13.500</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>ff</td>\n",
              "      <td>ff</td>\n",
              "      <td>2.000</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00200</td>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>b</td>\n",
              "      <td>17.92</td>\n",
              "      <td>0.205</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>aa</td>\n",
              "      <td>v</td>\n",
              "      <td>0.040</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>750</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>b</td>\n",
              "      <td>35.00</td>\n",
              "      <td>3.375</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>h</td>\n",
              "      <td>8.290</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00000</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
              "680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
              "681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
              "682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
              "683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
              "684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
              "685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
              "686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
              "687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
              "688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
              "689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvKrOQHbQYmm"
      },
      "source": [
        "Features 2, 7, 10 and 14 have numeric values (float64 and int64) -- all other features are non-numeric.\n",
        "\n",
        "The dataset also has varying ranges:\n",
        "Feaures 1 is in therange from 2-67\n",
        "\n",
        "The dataset has a number of missing values, which are labelled with a ?."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "cjHg9zsLPs-R",
        "outputId": "b1923807-af30-4347-e4cf-8495f5b44c9b"
      },
      "source": [
        "# Replace the missing value ?'s with NaNs.\n",
        "import numpy as np\n",
        "\n",
        "# Inspect the missing values\n",
        "print(applications.isnull().values.sum())\n",
        "\n",
        "# Replace the ?'s with NaNs\n",
        "applications = applications.replace('?', np.nan)\n",
        "\n",
        "# Check the missing values again to make sure they are different now\n",
        "applications.tail(20)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>670</th>\n",
              "      <td>b</td>\n",
              "      <td>47.17</td>\n",
              "      <td>5.835</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>5.500</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00465</td>\n",
              "      <td>150</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>b</td>\n",
              "      <td>25.83</td>\n",
              "      <td>12.835</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>cc</td>\n",
              "      <td>v</td>\n",
              "      <td>0.500</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00000</td>\n",
              "      <td>2</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>672</th>\n",
              "      <td>a</td>\n",
              "      <td>50.25</td>\n",
              "      <td>0.835</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>aa</td>\n",
              "      <td>v</td>\n",
              "      <td>0.500</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00240</td>\n",
              "      <td>117</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673</th>\n",
              "      <td>NaN</td>\n",
              "      <td>29.50</td>\n",
              "      <td>2.000</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>e</td>\n",
              "      <td>h</td>\n",
              "      <td>2.000</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00256</td>\n",
              "      <td>17</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674</th>\n",
              "      <td>a</td>\n",
              "      <td>37.33</td>\n",
              "      <td>2.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>i</td>\n",
              "      <td>h</td>\n",
              "      <td>0.210</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00260</td>\n",
              "      <td>246</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>675</th>\n",
              "      <td>a</td>\n",
              "      <td>41.58</td>\n",
              "      <td>1.040</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>aa</td>\n",
              "      <td>v</td>\n",
              "      <td>0.665</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00240</td>\n",
              "      <td>237</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>a</td>\n",
              "      <td>30.58</td>\n",
              "      <td>10.665</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>0.085</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>12</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00129</td>\n",
              "      <td>3</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>677</th>\n",
              "      <td>b</td>\n",
              "      <td>19.42</td>\n",
              "      <td>7.250</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>m</td>\n",
              "      <td>v</td>\n",
              "      <td>0.040</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>678</th>\n",
              "      <td>a</td>\n",
              "      <td>17.92</td>\n",
              "      <td>10.210</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>ff</td>\n",
              "      <td>ff</td>\n",
              "      <td>0.000</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00000</td>\n",
              "      <td>50</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679</th>\n",
              "      <td>a</td>\n",
              "      <td>20.08</td>\n",
              "      <td>1.250</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>v</td>\n",
              "      <td>0.000</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00000</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>b</td>\n",
              "      <td>19.50</td>\n",
              "      <td>0.290</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>k</td>\n",
              "      <td>v</td>\n",
              "      <td>0.290</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>364</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.000</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>d</td>\n",
              "      <td>h</td>\n",
              "      <td>3.000</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00176</td>\n",
              "      <td>537</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>b</td>\n",
              "      <td>17.08</td>\n",
              "      <td>3.290</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>i</td>\n",
              "      <td>v</td>\n",
              "      <td>0.335</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00140</td>\n",
              "      <td>2</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>b</td>\n",
              "      <td>36.42</td>\n",
              "      <td>0.750</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>d</td>\n",
              "      <td>v</td>\n",
              "      <td>0.585</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00240</td>\n",
              "      <td>3</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>b</td>\n",
              "      <td>40.58</td>\n",
              "      <td>3.290</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>m</td>\n",
              "      <td>v</td>\n",
              "      <td>3.500</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>s</td>\n",
              "      <td>00400</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>b</td>\n",
              "      <td>21.08</td>\n",
              "      <td>10.085</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>e</td>\n",
              "      <td>h</td>\n",
              "      <td>1.250</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00260</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>a</td>\n",
              "      <td>22.67</td>\n",
              "      <td>0.750</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>v</td>\n",
              "      <td>2.000</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>2</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00200</td>\n",
              "      <td>394</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>a</td>\n",
              "      <td>25.25</td>\n",
              "      <td>13.500</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>ff</td>\n",
              "      <td>ff</td>\n",
              "      <td>2.000</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00200</td>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>b</td>\n",
              "      <td>17.92</td>\n",
              "      <td>0.205</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>aa</td>\n",
              "      <td>v</td>\n",
              "      <td>0.040</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>750</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>b</td>\n",
              "      <td>35.00</td>\n",
              "      <td>3.375</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>h</td>\n",
              "      <td>8.290</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00000</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
              "670    b  47.17   5.835  u  g   w   v  5.500  f  f   0  f  g  00465  150  -\n",
              "671    b  25.83  12.835  u  g  cc   v  0.500  f  f   0  f  g  00000    2  -\n",
              "672    a  50.25   0.835  u  g  aa   v  0.500  f  f   0  t  g  00240  117  -\n",
              "673  NaN  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
              "674    a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
              "675    a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
              "676    a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
              "677    b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
              "678    a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
              "679    a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
              "680    b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
              "681    b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
              "682    b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
              "683    b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
              "684    b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
              "685    b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
              "686    a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
              "687    a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
              "688    b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
              "689    b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1aNCBkvSHUa"
      },
      "source": [
        "### Numeric Columns: Mean Imputation\n",
        "\n",
        "Missing values cannot be ignored -- they will affect the performance of our ML models. If we ignore them, the model will miss out on information in the dataset that is useful for training purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-5_9CB-SD5v",
        "outputId": "bbf21f04-f250-49fd-e7f7-f885151f17a6"
      },
      "source": [
        "# Mean imputation\n",
        "applications.fillna(applications.mean(), inplace=True)\n",
        "\n",
        "# Count the number of NaNs in the dataset to verify.\n",
        "# The remaining NaNs will be in the non-numeric columns\n",
        "print(applications.isnull().values.sum())\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SUnj6liTNOI"
      },
      "source": [
        "### Non-Numeric Columns: Highest Frequency Imputation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjWIyJQXS5_1",
        "outputId": "d8e493e2-857e-48fc-b517-03325b525482"
      },
      "source": [
        "# Iterate over each column\n",
        "for column in applications.columns:\n",
        "  if applications[column].dtypes == 'object':\n",
        "    applications = applications.fillna(applications[column].value_counts().index[0])\n",
        "\n",
        "# Count NaNs to verify\n",
        "print(applications.isnull().values.sum())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdnCbgueUS-I"
      },
      "source": [
        "# Data Preproccesing\n",
        "Missing values have been handled. \n",
        "\n",
        "There are three main tasks\n",
        "\n",
        "## 1. Convert non-numeric data to numeric.\n",
        "This results in faster computation -- sklearn and XGBoost typically require data to be in a numeric format\n",
        "\n",
        "## 2. Split the data into train, test sets\n",
        "This allows us to move into the training and testing phase of developing an ML model. We can do feature selection at the same time so that we train on only the most useful subset of features.\n",
        "\n",
        "## 3. Scale the feature values to a uniform range\n",
        "Features must be scaled before being fed into the ML model. Take CreditScore as an example, which is a measurement of someone's creditworthiness -- the higher the number, the more financially trustworthy a person is.\n",
        "\n",
        "If we scale CreditScore, a score of 1 is the highest, and 0 would be the lowest in a 0-1 range.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjZhkvoIUQag",
        "outputId": "d1cc87c0-f685-417c-84ad-2b3983317a5e"
      },
      "source": [
        "# 1. Convert non-numeric data to numeric\n",
        "# This can be done using label encoding\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Instantiate LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate over all the values of each column and extract their dtypes\n",
        "\n",
        "for column in applications.columns:\n",
        "  if applications[column].dtypes == 'object':\n",
        "    applications[column] = label_encoder.fit_transform(applications[column])\n",
        "\n",
        "# Check if all features are now of a numeric type\n",
        "applications.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       690 non-null    int64  \n",
            " 1   1       690 non-null    int64  \n",
            " 2   2       690 non-null    float64\n",
            " 3   3       690 non-null    int64  \n",
            " 4   4       690 non-null    int64  \n",
            " 5   5       690 non-null    int64  \n",
            " 6   6       690 non-null    int64  \n",
            " 7   7       690 non-null    float64\n",
            " 8   8       690 non-null    int64  \n",
            " 9   9       690 non-null    int64  \n",
            " 10  10      690 non-null    int64  \n",
            " 11  11      690 non-null    int64  \n",
            " 12  12      690 non-null    int64  \n",
            " 13  13      690 non-null    int64  \n",
            " 14  14      690 non-null    int64  \n",
            " 15  15      690 non-null    int64  \n",
            "dtypes: float64(2), int64(14)\n",
            "memory usage: 86.4 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhu31fXfXe0g"
      },
      "source": [
        "# 2. Split data into Train, Test sets\n",
        "\n",
        "# import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Drop features 11 and 13, and convert the DataFrame to a NumPy array\n",
        "applications = applications.drop([11,13], axis=1)\n",
        "applications = applications.values\n",
        "\n",
        "# Segregate features and labels into separate variables\n",
        "X, y = applications[:, 0:13], applications[:, 13]\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.33,\n",
        "                                                    random_state=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NB3C306ajDH"
      },
      "source": [
        "# 3. Scale the feature values to a uniform range\n",
        "\n",
        "# Import MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Instantiate MinMaxScaler to rescale Train and Test Inputs\n",
        "# Namely X_train and X_test\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Av_gyzbM7_S"
      },
      "source": [
        "## Fitting a Logistic Regression Model to the Train Set\n",
        "\n",
        "If we inspect the data, we will find that there is a higher proportion of \"Denied\" status applications than \"Approved\" status. Thus we can use this as a benchmark -- the model should be able to improve over the benchmark better than simply always choosing the highest frequency classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdyioYLPNU6E",
        "outputId": "3195c34e-d8bd-4827-d8c1-03b529b31382"
      },
      "source": [
        "# Import a GLM like Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate a LogReg classifier with default param values\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fit logreg to the training set which has been preprocessed\n",
        "logreg.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3saXwrdxNmiM",
        "outputId": "25087b2d-dae2-41d3-b8d0-daa2797155f0"
      },
      "source": [
        "# We can use a confusion matrix to check where the model is making mistakes\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Use logreg to predict instances from the test set and store it\n",
        "y_pred = logreg.predict(X_test_scaled)\n",
        "\n",
        "# Get the accuracy score of logreg\n",
        "print(\"Accuracy of logistic regression: \", logreg.score(X_test_scaled, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression:  0.8377192982456141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT5e7pOFOHLC",
        "outputId": "5d1cee1a-2a82-4d98-d79c-f604e05cb652"
      },
      "source": [
        "# Print the confusion matrix of the logreg model\n",
        "confusion_matrix(y_pred, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[92, 26],\n",
              "       [11, 99]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHaetXr7OLDU"
      },
      "source": [
        "## Evaluating and interpreting model accuracy\n",
        "\n",
        "The model yielded an accuracy score of 84%\n",
        "\n",
        "The confusion matrix is \n",
        "\n",
        "| 92 | 26 |\n",
        "|----|----|\n",
        "| 11 | 99 |\n",
        "\n",
        "The first element of the first row denotes the true negatives: the number of denied applications predicted correctly\n",
        "\n",
        "The last element of the 2nd row is the true positives -- the number of approved applications predicted correctly.\n",
        "\n",
        "\n",
        "                      \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TflE26aRDOw"
      },
      "source": [
        "### Using Grid Search to squeeze out some more model performance.\n",
        "\n",
        "Can define a grid of hyperparameter values and convert them into a single dictionary format which can be used by the sklearn package GridSearchCV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtoz9XeAN_d3",
        "outputId": "f4e8e099-403d-41da-9e80-2e408192346b"
      },
      "source": [
        "# Grid Search param grid\n",
        "\n",
        "# import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the grid of values\n",
        "tol = [0.01, 0.001, 0.0001]\n",
        "max_iter = [100, 150, 200]\n",
        "\n",
        "# Create a param grid\n",
        "param_grid = dict(tol=tol, max_iter = max_iter)\n",
        "print(param_grid)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tol': [0.01, 0.001, 0.0001], 'max_iter': [100, 150, 200]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tKsB7OYQ_cz",
        "outputId": "3e3c55e4-1851-4c00-8613-2a9683c7d97d"
      },
      "source": [
        "# Instantiate GridSearchCV() with the logreg model.\n",
        "\n",
        "grid_model = GridSearchCV(estimator=logreg, param_grid = param_grid, cv = 5)\n",
        "\n",
        "# Rescale features again\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit data to grid_model\n",
        "grid_model_result = grid_model.fit(X_scaled, y)\n",
        "\n",
        "# Summarize results\n",
        "best_score, best_params = (grid_model_result.best_score_,\n",
        "                          grid_model_result.best_params_)\n",
        "\n",
        "print(\"Best: %f using %s\" % (best_score, best_params))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.850725 using {'max_iter': 100, 'tol': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYSE3gtqShQw"
      },
      "source": [
        "### Evaluating Results and Conclusion\n",
        "\n",
        "In this notebook, an ML classifier was built using a Logistic Regression model, that takes into account the most important features that could be used to predict someone's credit-worthiness. GridSearch was performed to find optimal hyperparameters given the model, and an accuracy of 85% was obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LmYg-Yko7go"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}